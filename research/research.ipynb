{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d197642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26d2502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (41188, 21)\n",
      "\n",
      "Target distribution:\n",
      "y\n",
      "no     36548\n",
      "yes     4640\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"../data/bank-additional-full.csv\", sep=\";\")\n",
    "\n",
    "# Quick inspection\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df[\"y\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "029e93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable: yes -> 1, no -> 0\n",
    "df[\"y\"] = df[\"y\"].map({\"yes\": 1, \"no\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cccdeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "X = df.drop(\"y\", axis=1)\n",
    "y = df[\"y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f8d174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
      "Numerical Features: ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n"
     ]
    }
   ],
   "source": [
    "# identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical Features:\", categorical_features)\n",
    "print(\"Numerical Features:\", numerical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9558f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prerocessing pipelines for both numeric and categorical data\n",
    "# Decisions applied here:\n",
    "\n",
    "# One-Hot Encoding for categorical features\n",
    "\n",
    "# Standard Scaling for numerical features\n",
    "\n",
    "# \"unknown\" treated as a valid category\n",
    "\n",
    "# drop='first' to avoid multicollinearity\n",
    "\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_transformer = OneHotEncoder(\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\"\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f9d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "389e118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (32950, 20)\n",
      "Test shape: (8238, 20)\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc28334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train shape: (32950, 53)\n",
      "Processed test shape: (8238, 53)\n"
     ]
    }
   ],
   "source": [
    "# applying preprocessing pipelines to train and test data\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Processed train shape:\", X_train_processed.shape)\n",
    "print(\"Processed test shape:\", X_test_processed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28290354",
   "metadata": {},
   "source": [
    "Preprocessing completed, goal of the above preprocessing was to get\n",
    "\n",
    "X_train_processed\n",
    "\n",
    "X_test_processed\n",
    "\n",
    "y_train\n",
    "\n",
    "y_test\n",
    "\n",
    "preprocessor (to be reused in Streamlit)\n",
    "\n",
    "\n",
    "Moving to model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02e4d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c6ed5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating directory to save models\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \n",
    "    \"kNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "224bc30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training kNN...\n",
      "Training Naive Bayes...\n",
      "Training Random Forest...\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud/Documents/ml assignment/bank-marketing-subscription-prediction/.venv/lib64/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:35:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    trained_models[name] = model\n",
    "\n",
    "print(\"All models trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf4698d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# save model files\n",
    "\n",
    "\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    filename = name.lower().replace(\" \", \"_\") + \".pkl\"\n",
    "    joblib.dump(model, f\"model/{filename}\")\n",
    "\n",
    "print(\"All models saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a584893",
   "metadata": {},
   "source": [
    "Models trained now\n",
    "Going ahead with evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7dc60dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5c5b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Some models need predict_proba for AUC\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_prob = None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    return accuracy, auc, precision, recall, f1, mcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba1d0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    accuracy, auc, precision, recall, f1, mcc = evaluate_model(\n",
    "        model,\n",
    "        X_test_processed,\n",
    "        y_test\n",
    "    )\n",
    "    \n",
    "    results.append([\n",
    "        name,\n",
    "        accuracy,\n",
    "        auc,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1,\n",
    "        mcc\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b8ce1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ML Model Name  Accuracy       AUC  Precision    Recall  F1 Score  \\\n",
      "0  Logistic Regression  0.916242  0.942476   0.709507  0.434267  0.538770   \n",
      "1        Decision Tree  0.894513  0.741114   0.531085  0.543103  0.537027   \n",
      "2                  kNN  0.903496  0.876845   0.598227  0.436422  0.504673   \n",
      "3          Naive Bayes  0.844016  0.849316   0.383865  0.635776  0.478702   \n",
      "4        Random Forest  0.915878  0.947358   0.674074  0.490302  0.567686   \n",
      "5              XGBoost  0.919277  0.950366   0.662546  0.577586  0.617156   \n",
      "\n",
      "        MCC  \n",
      "0  0.513732  \n",
      "1  0.477549  \n",
      "2  0.459572  \n",
      "3  0.410839  \n",
      "4  0.530501  \n",
      "5  0.573958  \n"
     ]
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\n",
    "        \"ML Model Name\",\n",
    "        \"Accuracy\",\n",
    "        \"AUC\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"F1 Score\",\n",
    "        \"MCC\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c59f574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[7145  165]\n",
      " [ 525  403]]\n",
      "\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[6865  445]\n",
      " [ 424  504]]\n",
      "\n",
      "Confusion Matrix for kNN:\n",
      "[[7038  272]\n",
      " [ 523  405]]\n",
      "\n",
      "Confusion Matrix for Naive Bayes:\n",
      "[[6363  947]\n",
      " [ 338  590]]\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[7090  220]\n",
      " [ 473  455]]\n",
      "\n",
      "Confusion Matrix for XGBoost:\n",
      "[[7037  273]\n",
      " [ 392  536]]\n"
     ]
    }
   ],
   "source": [
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix for {name}:\")\n",
    "    print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
